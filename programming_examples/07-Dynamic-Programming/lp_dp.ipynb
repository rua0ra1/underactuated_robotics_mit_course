{"cells":[{"cell_type":"code","metadata":{"id":"A4QOaw_zYLfI","source_hash":"e27e2233","output_cleared":true,"execution_start":1644458971739,"execution_millis":1908,"deepnote_to_be_reexecuted":false,"cell_id":"f4771031f3754003b39f777c8e5769d2","deepnote_cell_type":"code"},"source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib import cm","block_group":"00001-142a6d01-32b5-4a15-aa12-c164d4e5d662","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"c6451ead498247fd8cd7bd5fdb3b67b6","deepnote_cell_type":"markdown"},"source":"# The Grid World\n\nWe have seen in class that we can obtain value function using [FittedValueIteration](https://deepnote.com/workspace/Underactuated-2ed1518a-973b-4145-bd62-1768b49956a8/project/526ff99b-f112-4247-9b0b-c52f0f88d6ce/notebook/on_a_mesh-44aac282aa1a436aafb2ac6ced3f1ccb). ","block_group":"00003-e23464ff-88d3-4b47-958a-88c8f84dfc52"},{"cell_type":"markdown","metadata":{"cell_id":"c5e5be38cb8c425f932879686ff0a3cd","deepnote_cell_type":"markdown"},"source":"## Linear Programming for Dynamic Programming\n\nFor our discrete grid world, let's try to obtain the optimal cost-to-go using [linear programming](https://underactuated.csail.mit.edu/lyapunov.html#LP). Linear Programming is an optimization program with linear objective functions as well as linear equality and inequality constraints. If you are not familiar with optimization, you could take a look at the linear programming [tutorial](https://github.com/RobotLocomotion/drake/blob/master/tutorials/linear_program.ipynb) in Drake. The following cells are setting up the grid world and the transition matrix $T$ in eq(14) in the textbook.","block_group":"00005-ed008a8e-b6be-4b57-9498-f0010fb963ab"},{"cell_type":"code","metadata":{"source_hash":"ad8aa506","output_cleared":true,"execution_start":1644439714617,"execution_millis":102,"deepnote_to_be_reexecuted":false,"cell_id":"76bce5ad4c8e4b00a5e0b7098cfcb320","deepnote_cell_type":"code"},"source":"xbins = range(0, 21)\nybins = range(0, 21)\n[X, Y] = np.meshgrid(xbins, ybins)\nstates = np.vstack((X.reshape(441), Y.reshape(441)))\n\n[ux, uy] = np.meshgrid([-1, 0, 1], [-1, 0, 1])\ninputs = np.vstack((ux.reshape(9), uy.reshape(9)))\n\ngoal = [2, 8]\n\n\ndef obstacle(x):\n    return x[0] >= 6 and x[0] <= 8 and x[1] >= 4 and x[1] <= 7\n\n\nA = np.eye(2)\nB = np.eye(2)\n\ninput_dim = inputs.shape[1]\nstate_dim = states.shape[1]\n\nT = np.zeros([state_dim, state_dim, input_dim])\n\nfor i in range(input_dim):\n    for j in range(state_dim):\n        next_state = A @ states[:, j] + B @ inputs[:, i]\n        ind = np.argmin(np.linalg.norm(states.T - next_state, axis=1))\n        T[j, ind, i] = 1","block_group":"00005-79c1e127-c5b6-44d4-835e-2c37185161db","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"13e753a6","output_cleared":true,"execution_start":1644439716636,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"749e0a3910104ebda406e6972fd6978e","deepnote_cell_type":"code"},"source":"def min_time_cost(x, u):\n    state_cost = 1\n    if obstacle(x):\n        state_cost = 10\n    if np.array_equal(x, goal):\n        state_cost = 0\n    action_cost = np.linalg.norm(u, 1)\n    if action_cost > 1:\n        action_cost = 10\n    return state_cost + action_cost","block_group":"00006-e49c4511-a352-4c6d-b9d3-15ed353abc97","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"3c8f080b8d7b47c59c05abd290d60db2","deepnote_cell_type":"markdown"},"source":"Now it's your turn to code up the linear program for solving the optimal cost-to-go. These Drake [tutorials](https://github.com/RobotLocomotion/drake/tree/master/tutorials) could be super helpful for setting up the optimization program. To deal with numerical instability, you should use a discount factor $\\gamma$ for the Bellman update: $$ J \\leq l(a) + \\gamma T(a) J, \\quad \\forall a.$$","block_group":"00007-d331d889-3006-43c0-a820-8984ec5585a1"},{"cell_type":"code","metadata":{"source_hash":"b972adf3","output_cleared":true,"deepnote_to_be_reexecuted":true,"cell_id":"92bad37a86a545d3a8c38d2d8b913514","deepnote_cell_type":"code"},"source":"import numpy as np\nfrom pydrake.solvers import MathematicalProgram, Solve\n\n# Create an empty MathematicalProgram named prog (with no decision variables,\n# constraints or costs)\nprog = MathematicalProgram()\nJ = prog.NewContinuousVariables(state_dim, \"J\")\n\ngamma = 0.99999\n\nfor i in range(input_dim):\n    l = np.zeros(state_dim)\n    for j in range(state_dim):\n        ## Calculate\n        l[j] = 0  # modify here\n        ## Modify here\n        ## Add Constraint for each entry of J\n\n\n## Modify here\n## Add cost to prog\n\n\nresult = Solve(prog)\nJ_value = np.reshape(result.GetSolution(J), X.shape)","block_group":"00008-e1c62275-3cdf-4482-bf3d-91d12da5737f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"b1f2a49044b34ab28697025d282ada9e","deepnote_cell_type":"markdown"},"source":"Let's visualize the value function you calculated using LP. It should be similiar to the plot obtained from FittedValueIteration.","block_group":"00010-de467e71-3ce0-4256-a888-b49a5603b84f"},{"cell_type":"code","metadata":{"source_hash":"53bd7a35","output_cleared":true,"execution_start":1644439733628,"execution_millis":195,"deepnote_output_heights":[280],"deepnote_to_be_reexecuted":false,"cell_id":"850aba867bab42528c6554b6e5149677","deepnote_cell_type":"code"},"source":"(fig, ax) = plt.subplots()\nax.set_xlabel(\"x\")\nax.set_ylabel(\"y\")\nax.set_title(\"Cost-to-Go\")\nk = ax.imshow(J_value, cmap=cm.jet)\nax.invert_yaxis()\nplt.colorbar(k)\nplt.show()","block_group":"00011-2ab52873-bb28-46fa-8dcc-80826da81f71","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"d4f4136fa9454c02b67f4cc9b7c67ac1","deepnote_cell_type":"markdown"},"source":"## Autograding\nYou can check your work by running the following cell:","block_group":"00012-36305c01-3e51-4723-8be0-f3fc9728f140"},{"cell_type":"code","metadata":{"source_hash":"8427ffb4","output_cleared":true,"execution_start":1644439736206,"execution_millis":1000,"deepnote_to_be_reexecuted":false,"cell_id":"4847223e91704a73ab0fc84d45de3584","deepnote_cell_type":"code"},"source":"from underactuated.exercises.dp.test_lp_dp import Testlpdp\nfrom underactuated.exercises.grader import Grader\n\nGrader.grade_output([Testlpdp], [locals()], \"results.json\")\nGrader.print_test_results(\"results.json\")","block_group":"00013-f5299738-e0e5-4ec8-9b8a-c4cb6ecdd304","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"b623e53d","output_cleared":true,"deepnote_to_be_reexecuted":true,"cell_id":"a2a61a97f34a4a63bd334f6cdc81c3da","deepnote_cell_type":"code"},"source":"","block_group":"00014-3bf31a41-9058-40e9-b82f-959f8ef2ff0c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=526ff99b-f112-4247-9b0b-c52f0f88d6ce' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"eaab123f7a094a22b8683cbb735c47f4","deepnote_execution_queue":[]}}